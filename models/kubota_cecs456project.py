# -*- coding: utf-8 -*-
"""Kubota_CECS456Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cfvcM1OdEkkEs8-JrjmwafFz_PVHTIxS

# Setup
"""

# Install necessary packages
!pip install opendatasets

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import sklearn
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

# For reading the dataset from Kaggle
import opendatasets as od
import pandas

# For reading the image file paths from the "Files" tab
import os

# For getting the actual images from "Files" tab, from a file path
import PIL
from PIL import Image

# For specifying variable types
from typing import Tuple

# Set the random seed
np.random.seed(42)

# Define some variables
labels = (0, 1, 2, 3, 4, 5, 6, 7)
label_strings = ("airplane", "car", "cat", "dog", "flower", "fruit", "motorbike", "person")
label_count = len(labels)

"""# Data setup"""

# Load the dataset from Kaggle


# Download Kaggle API token key from the Kaggle website while logged into your account
# Use this key to login when running this code block
dataset_path = "https://www.kaggle.com/datasets/prasunroy/natural-images"
od.download(dataset_path)

# Retrieves the data


# Returns the images and labels of all examples in the dataset
def load_dataset(dataset_directory: str):# -> Tuple[PIL.JpegImagePlugin.JpegImageFile, str]:
  x_temp, y_temp = [], []
  # Traverse through the directory
  for root, directories, files in os.walk(dataset_directory):
    for filename in files:
      # Join the strings to get the file's full path
      filepath = os.path.join(root, filename)
      for label in labels:
        # An example is labeled if its file path contains the label in its name
        if label_strings[label] in filename:
          x_temp.append(Image.open(filepath))
          y_temp.append(label)
  return x_temp, y_temp


natural_dataset_path = "natural-images/data/natural_images"
x_raw, y_raw = load_dataset(natural_dataset_path)
if len(x_raw) != len(y_raw):
  Exception("x train and y train have unequal sizes")
m = len(x_raw)

# Prepares the data before splitting it into training, validation, and test sets


# Returns the average dimension size of the entire dataset
def get_average_image_size(images):
  avg_height = 0
  avg_width = 0
  for image in images:
    avg_height += image.height
    avg_width += image.width
  avg_height /= m
  avg_width /= m
  avg_height = int(avg_height)
  avg_width = int(avg_width)
  return avg_height, avg_width


# Resizes all dataset images to be the same size
def resize_images(images, new_size):
  for i in range(len(images)):
    images[i] = images[i].resize(new_size)
  return images


avg_size = get_average_image_size(x_raw)
x_resized = resize_images(x_raw, avg_size)

# Starts splitting up the data


'''
For reference, output from HW 3 for set shapes
x train all  (60000, 28, 28)
y train all  (60000,)
x train  (55000, 28, 28)
y train  (55000,)
x dev  (5000, 28, 28)
y dev  (5000,)
x test  (10000, 28, 28)
y test  (10000,)
'''

# Maybe also try np.asarray and np.copy
x_train_all = np.array(x_resized)
y_train_all = np.array(y_raw)

# Another working way to split the datasets
# twenty_percent_split = int(m * 0.2)
# x_test = x_train_all[:twenty_percent_split]
# y_test = y_train_all[:twenty_percent_split]
# x_dev = x_train_all[twenty_percent_split:2 * twenty_percent_split]
# y_dev = y_train_all[twenty_percent_split:2 * twenty_percent_split]
# x_train = x_train_all[2 * twenty_percent_split:]
# y_train = y_train_all[2 * twenty_percent_split:]

# Split the datasets
# 60% training, 40% testing
x_train, x_test_all, y_train, y_test_all = train_test_split(x_train_all, y_train_all, test_size = 0.4, random_state = 42)
# From the 40% testing, it gets split into 20% validation and 20% (actual) testing
x_dev, x_test, y_dev, y_test = train_test_split(x_test_all, y_test_all, test_size = 0.5, random_state = 42)

print("x train all shape = ", x_train_all.shape)
print("y train all shape = ", y_train_all.shape)
print("x test shape = ", x_test.shape)
print("y test shape = ", y_test.shape)
print("x dev shape = ", x_dev.shape)
print("y dev shape = ", y_dev.shape)
print("x train shape = ", x_train.shape)
print("y train shape = ", y_train.shape)

testIndexes = (1111, 2222, 3333)
for testIndex in testIndexes:
  print(y_train_all[testIndex])
  plt.imshow(x_train_all[testIndex])
  plt.axis('off')
  plt.show()
  print()

"""# Model"""

# Builds the CNN model


model = tf.keras.models.Sequential()
# 3 = RGB channels
model_input_shape = [avg_size[1], avg_size[0], 3]

# # Convolution layer 1
# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation="relu", padding = "same",
#                                  input_shape = model_input_shape))
# # Pooling layer 1
# model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# # Convolution layer 2
# model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation="relu", padding = "same"))
# # Convolution layer 3
# model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation="relu", padding = "same"))
# # Pooling layer 2
# model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# # Convolution layer 4
# model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation="relu", padding = "same"))
# # Convolution layer 5
# model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation="relu", padding = "same"))
# # Pooling layer 3
# model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# # Flattening layer
# model.add(tf.keras.layers.Flatten())
# # Fully connected layer 1
# model.add(tf.keras.layers.Dense(units=128, activation="relu"))
# tf.keras.layers.Dropout(0.5)
# # Fully connected layer 2
# model.add(tf.keras.layers.Dense(units=64, activation="relu"))
# tf.keras.layers.Dropout(0.5)

# TODO Tweak this model to see if accuracy can be improved
# Add the first convolutional layer
model.add(Conv2D(32, (3, 3), activation='relu', input_shape = model_input_shape))
# Add a pooling layer
model.add(MaxPooling2D((2, 2)))
# Add another convolutional layer
model.add(Conv2D(64, (3, 3), activation='relu'))
# Add another pooling layer
model.add(MaxPooling2D((2, 2)))
# Add another convolutional layer
model.add(Conv2D(128, (3, 3), activation='relu'))
# Add another pooling layer
model.add(MaxPooling2D((2, 2)))
# Flatten the tensor output from the convolutional layers
model.add(Flatten())
# Add a dense layer
model.add(Dense(64, activation='relu'))

# Output layer
model.add(tf.keras.layers.Dense(units = label_count, activation= "softmax"))

model.summary()

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="adam",
              metrics=["accuracy"])

# The model in the CNN demo exhausts the free tier Colab resources
history = model.fit(
    x_train,
    y_train,
    batch_size = 100,
    epochs = 5,
    validation_data = (x_dev, y_dev))

# Prints loss and accuracy of the model's predictions


pre_predictions = model.predict(
    x = x_test,
    batch_size = 100
)

# Converts the arrays of probabilities (for each image being each label) to the actual labels
y_hat = np.argmax(pre_predictions, axis = 1)

total_loss = model.evaluate(x = x_test, y = y_hat)
print("Total loss =", total_loss)

print("Total loss? =", total_loss[0])
print("Total accuracy? =", total_loss[1])


total_correct = 0
total_examples = len(y_test)
for index in range(total_examples):
  if (y_test[index] == y_hat[index]):
    total_correct += 1
print("Total accuracy =", (total_correct / total_examples))

# Show predictions made


for i in range(10):
  print(f"Prediction #{i + 1}: Label = \"{label_strings[y_hat[i]]}\"")
  plt.imshow(x_test[i], cmap="binary")
  plt.axis('off')
  plt.show()
  print()